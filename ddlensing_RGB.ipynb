{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622b4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cached_property\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%run DDPM_for_pretrained.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89564607",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LensingDDPM:\n",
    "    @classmethod\n",
    "    def from_pretrained_astroddpm(cls, fname, *args, map_location=None, **kwargs):\n",
    "        diffusion = GaussianDiffusion(\n",
    "            Unet(dim=64, dim_mults=(1, 2, 4, 8)),\n",
    "            timesteps=1000, loss_type='l1'\n",
    "        ).eval()\n",
    "        \n",
    "        \n",
    "        diffusion.load_state_dict({\n",
    "            key[len('module.'):]: val for key, val in torch.load(\n",
    "                fname, map_location=map_location\n",
    "            )['model'].items()\n",
    "        })\n",
    "        return cls(diffusion.to(map_location), *args, **kwargs)\n",
    "\n",
    "    def __init__(self, diffusion: GaussianDiffusion, multi_channel=True, *, show_progress=True):\n",
    "        self.diffusion = diffusion\n",
    "        self.multi_channel = multi_channel\n",
    "        self.show_progress = show_progress\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.diffusion.parameters()).device\n",
    "\n",
    "    def with_progress(self, iterable):\n",
    "        return tqdm(iterable) if self.show_progress else iterable\n",
    "\n",
    "    @cached_property\n",
    "    def nchannels(self):\n",
    "        return self.diffusion.channels\n",
    "\n",
    "    @cached_property\n",
    "    def src_shape(self):\n",
    "        return (() if self.multi_channel else (self.nchannels,)) + 2*(self.diffusion.image_size,)\n",
    "\n",
    "    @cached_property\n",
    "    def ts(self):\n",
    "        return tuple(reversed(range(self.diffusion.num_timesteps)))\n",
    "\n",
    "    def prior(self, n=1, clip=False):\n",
    "        img = torch.randn((n, self.nchannels, *self.src_shape[-2:]), device=self.device)\n",
    "        for i in self.with_progress(self.ts):\n",
    "            img = self.diffusion.p_sample(\n",
    "                img, img.new_full((n,), i, dtype=torch.long),\n",
    "                clip_denoised=clip\n",
    "            )\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "class LensingDDRM(LensingDDPM):\n",
    "    def __init__(self, diffusion: GaussianDiffusion, Hb: Tensor,\n",
    "                 H: Tensor = None,\n",
    "                 U: Tensor = None, S: Tensor = None, Vh: Tensor = None,\n",
    "                 multi_channel=True, show_progress=True):\n",
    "        super().__init__(diffusion, multi_channel=multi_channel, show_progress=show_progress)\n",
    "\n",
    "        self.Hb = Hb\n",
    "        self.H = Hb.flatten(-2).flatten(-4,-3).flatten(0,1).flatten(1,2) if H is None else H\n",
    "        print(self.H.shape)\n",
    "        \n",
    "        if not self.multi_channel:\n",
    "            print('something happens here')\n",
    "            self.H = torch.cat(diffusion.channels * (self.H/diffusion.channels,), dim=-1)\n",
    "\n",
    "        if U is not None:\n",
    "            self.U, self.S, self.Vh = U, S, Vh\n",
    "        \n",
    "#         print(Hb.shape)\n",
    "#         print(self.Hb.shape[-4:-2])\n",
    "        \n",
    "    @cached_property\n",
    "    def img_mask(self):\n",
    "        return self.Hb.sum((-2, -1)) == 0\n",
    "\n",
    "    @cached_property\n",
    "    def img_shape(self):\n",
    "        return self.Hb.shape[-4:-2]\n",
    "\n",
    "    def _svd(self):\n",
    "        print('SVD-ing')\n",
    "        \n",
    "        self.H = self.H.float()\n",
    "        self.U, self.S, self.Vh = torch.linalg.svd(self.H, full_matrices=False)\n",
    "#         self.U = self.U.to(dtype=torch.float16)\n",
    "#         self.S = self.S.to(dtype=torch.float16)\n",
    "#         self.Vh = self.Vh.to(dtype=torch.float16)\n",
    "#         print('H shape',self.H.shape)\n",
    "#         print('U shape',self.U.shape)\n",
    "#         print('S shape',self.S.shape)\n",
    "#         print('V shape',self.Vh.shape)\n",
    "        \n",
    "    @cached_property\n",
    "    def U(self):\n",
    "        self._svd()\n",
    "        return self.U\n",
    "\n",
    "\n",
    "    @cached_property\n",
    "    def S(self):\n",
    "        self._svd()\n",
    "        return self.S\n",
    "\n",
    "    @cached_property\n",
    "    def Vh(self):\n",
    "        self._svd()\n",
    "        return self.Vh\n",
    "\n",
    "    @cached_property\n",
    "    def n(self) -> int:\n",
    "        return self.U.shape[-2]\n",
    "\n",
    "    @cached_property\n",
    "    def m(self) -> int:\n",
    "        return self.Vh.shape[-1]\n",
    "\n",
    "    @cached_property\n",
    "    def k(self) -> int:\n",
    "        return self.S.shape[-1]\n",
    "\n",
    "    def lens(self, src: Tensor):\n",
    "        return (self.Hb.flatten(-2).flatten(-3, -2) @ src.flatten(-2).unsqueeze(-1)).squeeze(-1).unflatten(-1, self.img_shape)\n",
    "\n",
    "    def mask(self, img: Tensor) -> np.ma.MaskedArray:\n",
    "        return np.ma.array(img, mask=self.img_mask.expand(img.shape))\n",
    "\n",
    "    @cached_property\n",
    "    def sqrt_alphas(self):\n",
    "        return self.diffusion.sqrt_alphas_cumprod\n",
    "\n",
    "    @cached_property\n",
    "    def sigmas(self):\n",
    "        return (self.sqrt_alphas**(-2) - 1)**0.5\n",
    "    \n",
    "    def steps(self, skip:int = 1, skip_type:str = \"linear\"):\n",
    "        \n",
    "        if skip_type == \"linear\":\n",
    "            steps = np.arange(0, self.diffusion.num_timesteps, skip)\n",
    "        elif skip_type == \"quad\":\n",
    "            steps = (\n",
    "                np.linspace(\n",
    "                    0, np.sqrt(self.diffusion.num_timesteps)*0.9999, self.diffusion.num_timesteps//skip\n",
    "                )\n",
    "                ** 2\n",
    "            )\n",
    "            steps = steps.astype(int)\n",
    "            steps = np.unique(steps) # Remove duplicates when skip is small\n",
    "\n",
    "        return steps\n",
    "\n",
    "    def project_y(self, y: Tensor):\n",
    "#         print(self.U.mT.shape)\n",
    "#         print(y.unsqueeze(-1).shape)\n",
    "        #y = y.half()\n",
    "\n",
    "#         self.U = self.U.half()\n",
    "#         self.S = self.S.half()\n",
    "        return (self.U.mT @ y.unsqueeze(-1)).squeeze(-1) / self.S\n",
    "\n",
    "    def project_x(self, x: Tensor):\n",
    "        return (self.Vh @ x.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    def deproject_x(self, xbar: Tensor):\n",
    "        return (self.Vh.mT @ xbar.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    def denoise(self, x: Tensor, t, clip=False):\n",
    "        \n",
    "        #print(self.src_shape)\n",
    "        x = x.to(device=DEVICE)\n",
    "        #print(x.shape)\n",
    "        src_shape = (3,256,256)\n",
    "        ximg = self.sqrt_alphas[t] * x.unflatten(-1, src_shape)\n",
    "        #print(ximg.shape)\n",
    "        if ximg.ndim < 4:\n",
    "            ximg = ximg.unsqueeze(-4)\n",
    "        t = torch.as_tensor(t).expand(ximg.shape[:-3])\n",
    "        t = t.to(device=DEVICE)\n",
    "\n",
    "        x_mean = self.diffusion.predict_start_from_noise(\n",
    "            ximg, t=t, noise=self.diffusion.denoise_fn(ximg, t))\n",
    "        if clip:\n",
    "            x_mean = x_mean.clip_(-1., 1.)\n",
    "        return x_mean.flatten(-len(self.src_shape))\n",
    "\n",
    "    def sample(self, y, sigma_y, eta=0.03, eta_b=0.85, skip=1, skip_type=\"linear\", clip=False):\n",
    "        steps = self.steps(skip=skip, skip_type=skip_type)\n",
    "        \n",
    "        sigma_y_scaled = sigma_y / self.S\n",
    "        r_sigma_y_scaled = self.S / sigma_y\n",
    "        var_y_scaled = sigma_y_scaled**2\n",
    "\n",
    "        y_bar = self.project_y(y).nan_to_num_(nan=None, posinf=1, neginf=1)\n",
    "\n",
    "        x = self.sigmas[steps[-1]] * torch.randn(\n",
    "            y.shape[:-1] + (self.m,),\n",
    "            device=y.device, dtype=y.dtype)\n",
    "\n",
    "        for t, tn in self.with_progress(zip(reversed(steps[:-1]), reversed(steps[1:]))):\n",
    "\n",
    "            sigma_t = self.sigmas[t]\n",
    "            eta_b_t = eta_b if eta_b is not None else 2 * self.S**2 / (self.S**2 + sigma_y**2 / sigma_t**2)\n",
    "\n",
    "            xnew = self.denoise(x, tn, clip=clip)\n",
    "            xnew = xnew.flatten(-2)\n",
    "\n",
    "            sdiff_pre = sigma_t * (1 - eta**2)**0.5\n",
    "\n",
    "            # Dealing with null-space\n",
    "#             print(x.shape)\n",
    "#             print(xnew.shape)\n",
    "            x_aux = xnew + sdiff_pre * (x - xnew) / self.sigmas[tn] + sigma_t * eta * torch.randn_like(x)\n",
    "\n",
    "            x0 = x_aux - ((self.Vh @ x_aux.unsqueeze(-1)).mT @ self.Vh).squeeze(-2)\n",
    "\n",
    "            x_bar = self.project_x(xnew)\n",
    "\n",
    "            # Dealing with non-singular-space\n",
    "            mask_constr = sigma_t > sigma_y_scaled\n",
    "            mean = torch.where(\n",
    "                mask_constr, torch.lerp(x_bar, y_bar, eta_b_t),\n",
    "                x_bar + sdiff_pre * (y_bar - x_bar) * r_sigma_y_scaled\n",
    "            )\n",
    "            var = torch.where(\n",
    "                mask_constr, sigma_t**2 - eta_b_t**2 * var_y_scaled,\n",
    "                             eta**2 * sigma_t**2\n",
    "            ).clip_(0)\n",
    "\n",
    "            x12 = mean + var**0.5 * torch.randn_like(y_bar)\n",
    "\n",
    "            x = x0 + (self.Vh.T @ x12.unsqueeze(-1)).squeeze(-1)\n",
    "            \n",
    "            #print(x.shape)\n",
    "\n",
    "        return self.denoise(x, 0, clip=clip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
