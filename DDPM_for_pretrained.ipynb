{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047e1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "\n",
    "from torch.utils import data\n",
    "from pathlib import Path\n",
    "from torch.optim import Adam\n",
    "from torchvision import utils\n",
    "from skimage.transform import resize\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "\n",
    "from time import time\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#   _   _      _\n",
    "#  | | | | ___| |_ __   ___ _ __ ___\n",
    "#  | |_| |/ _ \\ | '_ \\ / _ \\ '__/ __|\n",
    "#  |  _  |  __/ | |_) |  __/ |  \\__ \\\n",
    "#  |_| |_|\\___|_| .__/ \\___|_|  |___/\n",
    "#               |_|\n",
    "\n",
    "def default(val, d):\n",
    "    if val is not None:\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "def cycle(dl):\n",
    "    while True:\n",
    "        for data in dl:\n",
    "            yield data\n",
    "\n",
    "def num_to_groups(num, divisor):\n",
    "    groups = num // divisor\n",
    "    remainder = num % divisor\n",
    "    arr = [divisor] * groups\n",
    "    if remainder > 0:\n",
    "        arr.append(remainder)\n",
    "    return arr\n",
    "\n",
    "class EMA():\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def update_model_average(self, ma_model, current_model):\n",
    "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "            old_weight, up_weight = ma_params.data, current_params.data\n",
    "            ma_params.data = self.update_average(old_weight, up_weight)\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(F.softplus(x))\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.InstanceNorm2d(dim, affine = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "class Rezero(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.g = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) * self.g\n",
    "\n",
    "#   ____        _ _     _ _               _     _            _\n",
    "#  | __ ) _   _(_) | __| (_)_ __   __ _  | |__ | | ___   ___| | _____\n",
    "#  |  _ \\| | | | | |/ _` | | '_ \\ / _` | | '_ \\| |/ _ \\ / __| |/ / __|\n",
    "#  | |_) | |_| | | | (_| | | | | | (_| | | |_) | | (_) | (__|   <\\__ \\\n",
    "#  |____/ \\__,_|_|_|\\__,_|_|_| |_|\\__, | |_.__/|_|\\___/ \\___|_|\\_\\___/\n",
    "#                                 |___/\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups = 8):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim_out, 3, padding=1),\n",
    "            nn.GroupNorm(groups, dim_out),\n",
    "            Mish()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim, groups = 8):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            Mish(),\n",
    "            nn.Linear(time_emb_dim, dim_out)\n",
    "        )\n",
    "\n",
    "        self.block1 = Block(dim, dim_out)\n",
    "        self.block2 = Block(dim_out, dim_out)\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        h = self.block1(x)\n",
    "        h += self.mlp(time_emb)[:, :, None, None]\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n",
    "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "        q, k, v = rearrange(qkv, 'b (qkv heads c) h w -> qkv b heads c (h w)', heads = self.heads, qkv=3)\n",
    "        k = k.softmax(dim=-1)\n",
    "        context = torch.einsum('bhdn,bhen->bhde', k, v)\n",
    "        out = torch.einsum('bhde,bhdn->bhen', context, q)\n",
    "        out = rearrange(out, 'b heads c (h w) -> b (heads c) h w', heads=self.heads, h=h, w=w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "#   _   _            _                         _      _\n",
    "#  | | | |_ __   ___| |_   _ __ ___   ___   __| | ___| |\n",
    "#  | | | | '_ \\ / _ \\ __| | '_ ` _ \\ / _ \\ / _` |/ _ \\ |\n",
    "#  | |_| | | | |  __/ |_  | | | | | | (_) | (_| |  __/ |\n",
    "#   \\___/|_| |_|\\___|\\__| |_| |_| |_|\\___/ \\__,_|\\___|_|\n",
    "#\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        out_dim = None,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        groups = 8,\n",
    "        channels = 3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        dims = [channels, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        self.time_pos_emb = SinusoidalPosEmb(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            Mish(),\n",
    "            nn.Linear(dim * 4, dim)\n",
    "        )\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(nn.ModuleList([\n",
    "                ResnetBlock(dim_in, dim_out, time_emb_dim = dim),\n",
    "                ResnetBlock(dim_out, dim_out, time_emb_dim = dim),\n",
    "                Residual(Rezero(LinearAttention(dim_out))),\n",
    "                Downsample(dim_out) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = ResnetBlock(mid_dim, mid_dim, time_emb_dim = dim)\n",
    "        self.mid_attn = Residual(Rezero(LinearAttention(mid_dim)))\n",
    "        self.mid_block2 = ResnetBlock(mid_dim, mid_dim, time_emb_dim = dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append(nn.ModuleList([\n",
    "                ResnetBlock(dim_out * 2, dim_in, time_emb_dim = dim),\n",
    "                ResnetBlock(dim_in, dim_in, time_emb_dim = dim),\n",
    "                Residual(Rezero(LinearAttention(dim_in))),\n",
    "                Upsample(dim_in) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        out_dim = default(out_dim, channels)\n",
    "        self.final_conv = nn.Sequential(\n",
    "            Block(dim, dim),\n",
    "            nn.Conv2d(dim, out_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        t = self.time_pos_emb(time)\n",
    "        t = self.mlp(t)\n",
    "\n",
    "        h = []\n",
    "\n",
    "        for resnet, resnet2, attn, downsample in self.downs:\n",
    "            x = resnet(x, t)\n",
    "            x = resnet2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        for resnet, resnet2, attn, upsample in self.ups:\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = resnet(x, t)\n",
    "            x = resnet2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "#    ____                     _                   _ _  __  __           _\n",
    "#   / ___| __ _ _   _ ___ ___(_) __ _ _ __     __| (_)/ _|/ _|_   _ ___(_) ___  _ __\n",
    "#  | |  _ / _` | | | / __/ __| |/ _` | '_ \\   / _` | | |_| |_| | | / __| |/ _ \\| '_ \\\n",
    "#  | |_| | (_| | |_| \\__ \\__ \\ | (_| | | | | | (_| | |  _|  _| |_| \\__ \\ | (_) | | | |\n",
    "#   \\____|\\__,_|\\__,_|___/___/_|\\__,_|_| |_|  \\__,_|_|_| |_|  \\__,_|___/_|\\___/|_| |_|\n",
    "#\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    b, *_ = t.shape\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "def noise_like(shape, device, repeat=False):\n",
    "    repeat_noise = lambda: torch.randn((1, *shape[1:]), device=device).repeat(shape[0], *((1,) * (len(shape) - 1)))\n",
    "    noise = lambda: torch.randn(shape, device=device)\n",
    "    return repeat_noise() if repeat else noise()\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s = 0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule\n",
    "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = np.linspace(0, steps, steps)\n",
    "    alphas_cumprod = np.cos(((x / steps) + s) / (1 + s) * np.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return np.clip(betas, a_min = 0, a_max = 0.999)\n",
    "\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        denoise_fn,\n",
    "        *,\n",
    "        image_size = 256,\n",
    "        channels = 3,\n",
    "        timesteps = 1000,\n",
    "        loss_type = 'l1',\n",
    "        betas = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.denoise_fn = denoise_fn\n",
    "\n",
    "        if betas is not None:\n",
    "            betas = betas.detach().cpu().numpy() if isinstance(betas, torch.Tensor) else betas\n",
    "        else:\n",
    "            betas = cosine_beta_schedule(timesteps)\n",
    "\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n",
    "\n",
    "        timesteps, = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        to_torch = partial(torch.tensor, dtype=torch.float32)\n",
    "\n",
    "        self.register_buffer('betas', to_torch(betas))\n",
    "        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n",
    "        self.register_buffer('alphas_cumprod_prev', to_torch(alphas_cumprod_prev))\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.register_buffer('sqrt_alphas_cumprod', to_torch(np.sqrt(alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod', to_torch(np.sqrt(1. - alphas_cumprod)))\n",
    "        self.register_buffer('log_one_minus_alphas_cumprod', to_torch(np.log(1. - alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recip_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recipm1_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
    "        self.register_buffer('posterior_variance', to_torch(posterior_variance))\n",
    "        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n",
    "        self.register_buffer('posterior_log_variance_clipped', to_torch(np.log(np.maximum(posterior_variance, 1e-20))))\n",
    "        self.register_buffer('posterior_mean_coef1', to_torch(\n",
    "            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n",
    "        self.register_buffer('posterior_mean_coef2', to_torch(\n",
    "            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n",
    "\n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        mean = extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "        variance = extract(1. - self.alphas_cumprod, t, x_start.shape)\n",
    "        log_variance = extract(self.log_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
    "            extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        posterior_mean = (\n",
    "            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n",
    "            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = extract(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, x, t, clip_denoised: bool):\n",
    "        x_recon = self.predict_start_from_noise(x, t=t, noise=self.denoise_fn(x, t))\n",
    "\n",
    "        if clip_denoised:\n",
    "            x_recon.clamp_(-1., 1.)\n",
    "\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t, clip_denoised=True, repeat_noise=False):\n",
    "        b, *_, device = *x.shape, x.device\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(x=x, t=t, clip_denoised=clip_denoised)\n",
    "        noise = noise_like(x.shape, device, repeat_noise)\n",
    "        # no noise when t == 0\n",
    "        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n",
    "        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, shape):\n",
    "        device = self.betas.device\n",
    "\n",
    "        b = shape[0]\n",
    "        img = torch.randn(shape, device=device)\n",
    "\n",
    "        for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "            img = self.p_sample(img, torch.full((b,), i, device=device, dtype=torch.long))\n",
    "        return img\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, image_size, batch_size = 16):\n",
    "        image_size = self.image_size\n",
    "        channels = self.channels\n",
    "        return self.p_sample_loop((batch_size, channels, image_size, image_size))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def interpolate(self, x1, x2, t = None, lam = 0.5):\n",
    "        b, *_, device = *x1.shape, x1.device\n",
    "        t = default(t, self.num_timesteps - 1)\n",
    "\n",
    "        assert x1.shape == x2.shape\n",
    "\n",
    "        t_batched = torch.stack([torch.tensor(t, device=device)] * b)\n",
    "        xt1, xt2 = map(lambda x: self.q_sample(x, t=t_batched), (x1, x2))\n",
    "\n",
    "        img = (1 - lam) * xt1 + lam * xt2\n",
    "        for i in tqdm(reversed(range(0, t)), desc='interpolation sample time step', total=t):\n",
    "            img = self.p_sample(img, torch.full((b,), i, device=device, dtype=torch.long))\n",
    "\n",
    "        return img\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def q_then_p(self, x_start, t, batch_size=16, mask=None):\n",
    "        device = self.betas.device\n",
    "        if mask is not None:\n",
    "            mask = torch.stack([mask] * batch_size)\n",
    "            x_start = torch.where(mask == True, torch.tensor(-1.0).to(\"cuda\"), x_start)\n",
    "\n",
    "        if t == 1000:\n",
    "            zs = torch.randn(x_start.shape, device=device)\n",
    "        else:\n",
    "            zs = self.q_sample(x_start, torch.tensor([t] * batch_size).to(device))\n",
    "        ps = zs\n",
    "        for i in tqdm(reversed(range(0, t)), desc='domain transfer time step', total=t):\n",
    "            if mask is not None:\n",
    "                zs = self.q_sample(x_start, torch.tensor([i] * batch_size).to(device))\n",
    "                ps = torch.where(mask == False, zs, ps)\n",
    "\n",
    "            ps = self.p_sample(ps, torch.full((batch_size,), i, device=device, dtype=torch.long))\n",
    "\n",
    "        #if mask is not None:\n",
    "        #    ps = self.p_sample(ps, torch.full((batch_size,), i, device=device, dtype=torch.long))\n",
    "        #    ps = torch.where(mask == False, x_start, ps)\n",
    "\n",
    "        return ps\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        return (\n",
    "            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
    "            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n",
    "        )\n",
    "\n",
    "    def p_losses(self, x_start, t, noise = None):\n",
    "        b, c, h, w = x_start.shape\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n",
    "        x_recon = self.denoise_fn(x_noisy, t)\n",
    "\n",
    "        if self.loss_type == 'l1':\n",
    "            loss = (noise - x_recon).abs().mean()\n",
    "        elif self.loss_type == 'l2':\n",
    "            loss = F.mse_loss(noise, x_recon)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        b, c, h, w, device = *x.shape, x.device\n",
    "        t = torch.randint(0, self.num_timesteps, (b,), device=device).long()\n",
    "        return self.p_losses(x, t, *args, **kwargs)\n",
    "\n",
    "#   ____        _                 _          _\n",
    "#  |  _ \\  __ _| |_ __ _ ___  ___| |_    ___| | __ _ ___ ___\n",
    "#  | | | |/ _` | __/ _` / __|/ _ \\ __|  / __| |/ _` / __/ __|\n",
    "#  | |_| | (_| | || (_| \\__ \\  __/ |_  | (__| | (_| \\__ \\__ \\\n",
    "#  |____/ \\__,_|\\__\\__,_|___/\\___|\\__|  \\___|_|\\__,_|___/___/\n",
    "#\n",
    "\n",
    "class Galaxies(data.Dataset):\n",
    "    def __init__(self, folder, image_size, minmaxnorms=(0, 5.5), n_pix=None):\n",
    "        super().__init__()\n",
    "        self.folder = folder\n",
    "        self.image_size = image_size\n",
    "        self.paths = list(Path(f'{folder}').glob(f'**/*.npy'))\n",
    "        self.min_ = minmaxnorms[0]\n",
    "        self.max_ = minmaxnorms[1]\n",
    "        self.n_pix = n_pix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        img = np.load(path)\n",
    "\n",
    "        img = np.clip(img, self.min_, self.max_)\n",
    "        img = 2*(img - self.min_)/(self.max_ - self.min_) - 1 # A min max norm for all maxima == 5 and minima == 0.0 gals\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            img = np.flip(img, axis=1)\n",
    "        if np.random.rand() > 0.5:\n",
    "            img = np.flip(img, axis=2)\n",
    "\n",
    "        if self.n_pix is not None:\n",
    "            img = resize(img, (self.n_pix, self.n_pix))\n",
    "\n",
    "        img = img.copy()\n",
    "        return torch.tensor(img)\n",
    "\n",
    "#   _____          _                        _\n",
    "#  |_   _| __ __ _(_)_ __   ___ _ __    ___| | __ _ ___ ___\n",
    "#    | || '__/ _` | | '_ \\ / _ \\ '__|  / __| |/ _` / __/ __|\n",
    "#    | || | | (_| | | | | |  __/ |    | (__| | (_| \\__ \\__ \\\n",
    "#    |_||_|  \\__,_|_|_| |_|\\___|_|     \\___|_|\\__,_|___/___/\n",
    "#\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        diffusion_model,\n",
    "        folder,\n",
    "        *,\n",
    "        ema_decay = 0.995,\n",
    "        image_size = 256,\n",
    "        train_batch_size = 32,\n",
    "        train_lr = 2e-5,\n",
    "        train_num_steps = 100000,\n",
    "        gradient_accumulate_every = 2,\n",
    "        fp16 = False,\n",
    "        step_start_ema = 2000,\n",
    "        update_ema_every = 10,\n",
    "        rank = [0, 1, 2],\n",
    "        num_workers = 128,\n",
    "        save_every = 5000,\n",
    "        sample_every = 5000,\n",
    "        logdir = './logs',\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.DataParallel(diffusion_model, device_ids=rank)\n",
    "        self.ema = EMA(ema_decay)\n",
    "        self.ema_model = copy.deepcopy(self.model)\n",
    "        self.update_ema_every = update_ema_every\n",
    "\n",
    "        self.step_start_ema = step_start_ema\n",
    "        self.save_every = save_every\n",
    "        self.sample_every = sample_every\n",
    "\n",
    "        self.batch_size = train_batch_size\n",
    "        self.image_size = image_size\n",
    "        self.gradient_accumulate_every = gradient_accumulate_every\n",
    "        self.train_num_steps = train_num_steps\n",
    "\n",
    "        self.logdir = Path(logdir)\n",
    "        self.logdir.mkdir(exist_ok = True)\n",
    "\n",
    "        self.ds = Galaxies(folder, image_size, minmaxnorms=(0, 5.5))\n",
    "        self.dl = cycle(data.DataLoader(self.ds, batch_size = train_batch_size, shuffle=True, num_workers=num_workers))\n",
    "        self.opt = Adam(diffusion_model.parameters(), lr=train_lr)\n",
    "\n",
    "        self.step = 0\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.ema_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def step_ema(self):\n",
    "        if self.step < self.step_start_ema:\n",
    "            self.reset_parameters()\n",
    "            return\n",
    "        self.ema.update_model_average(self.ema_model, self.model)\n",
    "\n",
    "    def save(self, milestone):\n",
    "        data = {\n",
    "            'step': self.step,\n",
    "            'model': self.model.state_dict(),\n",
    "            'ema': self.ema_model.state_dict()\n",
    "        }\n",
    "        torch.save(data, str(self.logdir / f'{milestone:08d}-model.pt'))\n",
    "\n",
    "    def load(self, milestone):\n",
    "        data = torch.load(str(self.logdir / f'{milestone:08d}-model.pt'))\n",
    "\n",
    "        self.step = data['step']\n",
    "        self.model.load_state_dict(data['model'])\n",
    "        self.ema_model.load_state_dict(data['ema'])\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        t1 = time()\n",
    "        while self.step < self.train_num_steps:\n",
    "            for i in range(self.gradient_accumulate_every):\n",
    "                data = next(self.dl).to(device=DEVICE)\n",
    "                while torch.any(~torch.isfinite(data)):\n",
    "                    print(\"NAN DETECTED!!\")\n",
    "                    data = next(self.dl).to(device=DEVICE)\n",
    "                loss = self.model(data).sum()\n",
    "                t0 = time()\n",
    "                print(f'{self.step}: {loss.item()}, delta_t: {t0 - t1:.03f}')\n",
    "                t1 = time()\n",
    "                with open(str(self.logdir / 'loss.txt'), 'a') as df:\n",
    "                    df.write(f'{self.step},{loss.item()}\\n')\n",
    "                (loss / self.gradient_accumulate_every).backward()\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            if self.step % self.update_ema_every == 0:\n",
    "                self.step_ema()\n",
    "\n",
    "            if self.step % self.sample_every == 0:\n",
    "                batches = num_to_groups(18, self.batch_size)\n",
    "                all_images_list = list(map(lambda n: self.ema_model.module.sample(self.image_size, batch_size=n), batches))\n",
    "                all_images = torch.cat(all_images_list, dim=0)\n",
    "                all_images = torch.flip(all_images, dims=[1]) # map channels correctly for imout\n",
    "                all_images = all_images + 1\n",
    "                all_images = list(map(lambda x: (x - x.min())/(x.max() - x.min()), all_images))\n",
    "                utils.save_image(all_images, str(self.logdir / f'{self.step:08d}-sample.jpg'), nrow=6)\n",
    "\n",
    "            if self.step != 0 and self.step % self.save_every == 0:\n",
    "                self.save(self.step)\n",
    "\n",
    "            self.step += 1\n",
    "\n",
    "        print('training completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
